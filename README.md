# Mesh3D Generator - GeraÃ§Ã£o de Malhas 3D a partir de Imagens

Projeto de VisÃ£o Computacional para gerar malhas 3D a partir de uma ou mais imagens, utilizando LLM multimodal para gerar descriÃ§Ãµes extremamente detalhadas da cena que guiam o refinamento da malha.

## Estrutura do Projeto

```mermaid
graph TD
    A[Input Image] --> B[Florence-2 Caption]
    B --> C[LLM Refinamento de Prompt]
    C --> D{pipeline_mode}

    %% Multiview Branch
    D -->|multiview| M1[Zero123PP Multiview]
    M1 --> M2[LRM Reconstrucao]
    M2 --> M3[ISOMER Refinamento]
    M3 --> M4[Export OBJ/GLB]

    %% Flux Branch
    D -->|flux| F1[Flux + ControlNet + Redux]
    F1 --> F2[LRM Reconstrucao]
    F2 --> F3[ISOMER Refinamento]
    F3 --> F4[Export OBJ/GLB]

    %% Checkpoints
    C --> CP1[Checkpoint caption.txt]
    M1 --> CP2[Checkpoint mv_images]
    M2 --> CP3[Checkpoint mv_mesh.glb]
    F1 --> CP4[Checkpoint flux_bundle.png]
    F2 --> CP5[Checkpoint flux_mesh.glb]
```

## ğŸ“‹ Objetivo

Gerar uma malha 3D a partir de uma ou mais imagens, onde primeiro um texto descritivo da cena serÃ¡ gerado utilizando LLM para gerar o texto extremamente detalhado. O normal map e outras informaÃ§Ãµes serÃ£o usadas de forma que a malha seja refinada de acordo com o texto e com essas tÃ©cnicas.

## ğŸ¯ Pipeline do Projeto

O projeto segue o seguinte pipeline:

1. **GeraÃ§Ã£o de Texto Detalhado com LLM**: AnÃ¡lise da(s) imagem(ns) usando LLM multimodal (llava/bakllava) para gerar descriÃ§Ã£o extremamente detalhada da cena
2. **GeraÃ§Ã£o de Normal Maps**: ExtraÃ§Ã£o de normal maps a partir da imagem de entrada
3. **InicializaÃ§Ã£o da Malha**: CriaÃ§Ã£o da malha inicial usando LRM ou Sphere init (InstantMesh)
4. **Refinamento da Malha**: Melhoria da malha usando ControlNet-Tile e ControlNet-Normal + texto descritivo detalhado gerado pelo LLM

## ğŸš€ InstalaÃ§Ã£o

## âš™ï¸ Ambiente e DependÃªncias

### Requisitos mÃ­nimos de hardware

| Recurso | MÃ­nimo | Recomendado |
|---------|--------|-------------|
| GPU      | 12â€¯GB VRAM (RTX 3060 Ti / 4070) | 24â€¯GB+ (RTX 4090 / A6000) |
| RAM      | 32â€¯GB                          | 64â€¯GB+                    |
| Disco    | 60â€¯GB livres (modelos + cache) | 120â€¯GB                    |

> **AtenÃ§Ã£o**: o pipeline carrega mÃºltiplos modelos (Flux, ControlNet, Zero123++, LRM, ISOMER, Florence-2). Com 12â€¯GB de VRAM Ã© obrigatÃ³rio usar `--fast-mode` (ativa offload agressivo e reduz steps). Em VRAM menores que 10â€¯GB o pipeline Flux nÃ£o cabe.

### PrÃ©-requisitos de software

- **Python 3.11.9** (OBRIGATÃ“RIO)
- **CUDA Toolkit 12.4** (funciona com 12.1/12.2; 11.x nÃ£o Ã© suportado pela versÃ£o atual do FLUX)
- **Visual Studio Build Tools 2019** (componentes â€œDesktop development with C++â€ para compilar `renderutils_plugin`)
- **Ninja** (jÃ¡ incluÃ­do no repositÃ³rio, mas mantenha no `PATH` para garantir)
- **Conta HuggingFace** autenticada (`huggingface-cli login`)
- **Git LFS** para baixar checkpoints grandes

### RepositÃ³rios necessÃ¡rios

Este projeto incorpora o **Kiss3DGen** como submÃ³dulo/pasta. A organizaÃ§Ã£o recomendada:

```
D:\Visao_Computacional\2025_2\
â”œâ”€â”€ mesh3d-generator (este repo)
â”œâ”€â”€ Kiss3DGen (jÃ¡ incluso dentro de mesh3d-generator/Kiss3DGen)
â””â”€â”€ data\
    â””â”€â”€ raw\gazebo_dataset\images\*.jpg  # dataset local
```

Se quiser trabalhar fora desta estrutura, mantenha a variÃ¡vel `PROJECT_ROOT` apontando para a pasta que contÃ©m `Kiss3DGen/`.

### Modelos necessÃ¡rios

| Modelo                         | Origem                                  | Destino                                                     |
|-------------------------------|-----------------------------------------|-------------------------------------------------------------|
| `flux1-dev-fp8.safetensors`   | HuggingFace                             | `models/`                                                   |
| ControlNet (`Union`)          | HuggingFace                             | `checkpoint/flux_controlnet/`                               |
| LoRA Redux (`Flux.1-Redux`)   | HuggingFace                             | `checkpoint/flux_lora/`                                     |
| `Zero123++` + UNet custom     | Release Kiss3DGen                       | `models/zero123plus/`                                       |
| `LRM final_ckpt.ckpt`         | Release LRM                             | `Kiss3DGen/checkpoint/lrm/`                                 |
| `Florence-2 large no flash`   | HuggingFace                             | cache automÃ¡tico em `Kiss3DGen/.cache/`                     |
| Assets ISOMER / nvdiffrast    | IncluÃ­dos                               | `Kiss3DGen/models/ISOMER/`                                  |

Use `python scripts/download_models.py` para Flux/ControlNet/Zero123, e `python scripts/download_lrm.py` para o LRM. Verifique se os diretÃ³rios aparecem conforme tabela.

### Issues conhecidas / falhas esperadas

| Sintoma | Causa | MitigaÃ§Ã£o |
|---------|-------|-----------|
| `renderutils_plugin` recompila a cada run e falha com `LNK1104` | plugin tenta re-linkar dentro de `%APPDATA%` sem permissÃµes | Defina `TORCH_EXTENSIONS_DIR=D:\...\torch_extensions_cache` e prÃ©-compile com `python scripts/precompile_nvdiffrast.py --clean`. Se falhar, copie manualmente `renderutils_plugin.pyd` liberado pelo time para `mesh3d-generator-py3.11\Lib\site-packages`. |
| Objetos saem dessaturados (tons de cinza) | LRM gera vertex colors em float 0â€“1 e o export/clamp estava convertendo indevidamente | Atualizamos `save_py3dmesh_with_trimesh_fast_local` para preservar sRGB e exportar RGBA uint8. Se ainda notar cores lavadas, verifique `outputs/tmp/*_recon_from_kiss3d.png`: se jÃ¡ estiverem cinza, o problema vem do bundle (revise a imagem de entrada/caption). |
| VRAM insuficiente / OOM | `pipeline_mode=flux` carrega Flux+ControlNet+Zero123++/LRM simultaneamente | Use `--fast-mode` (desativa Redux/ControlNet e libera VRAM agressivamente), reduza `num_inference_steps`, ou opere em `--pipeline-mode multiview`. |

### Fluxo completo de instalaÃ§Ã£o (Windows)

#### Setup RÃ¡pido

```powershell
# 1. Instalar Python 3.11.9
# Baixar de: https://www.python.org/downloads/release/python-3119/
# Marcar "Add Python to PATH" durante instalaÃ§Ã£o

# 2. Configurar ambiente virtual Python 3.11.9
.\scripts\setup_python311.ps1
# OU
.\scripts\setup_python311.bat

# 3. Ativar ambiente virtual
.\mesh3d-generator-py3.11\Scripts\Activate.ps1

# 4. Instalar PyTorch com CUDA (ajustar versÃ£o CUDA conforme sua GPU)
pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu121

# 5. Instalar todas as dependÃªncias
pip install -r requirements.txt
# OU usar script automatizado:
python scripts/install_dependencies.py

# 6. Instalar diffusers customizado do Kiss3DGen
cd Kiss3DGen
pip install -e custom_diffusers/
cd ..

# 7. Autenticar no HuggingFace
huggingface-cli login
# OU
python scripts/setup_huggingface_auth.py

# 8. Baixar modelos necessÃ¡rios
python scripts/download_models.py
python scripts/download_redux.py  # Opcional
python scripts/download_lrm.py   # Opcional
# 9. PrÃ©-compilar renderutils_plugin (nvdiffrast)
python scripts/precompile_nvdiffrast.py --clean
```

#### Setup Manual

```bash
# 1. Criar ambiente virtual com Python 3.11.9
python3.11 -m venv mesh3d-generator-py3.11

# 2. Ativar ambiente virtual
# Windows:
.\mesh3d-generator-py3.11\Scripts\activate
# Linux/Mac:
source mesh3d-generator-py3.11/bin/activate

# 3. Atualizar pip
pip install --upgrade pip setuptools wheel

# 4. Instalar PyTorch com CUDA
pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu121

# 5. Instalar dependÃªncias
pip install -r requirements.txt

# 6. Instalar pacotes via git (requer Visual Studio Build Tools no Windows)
pip install git+https://github.com/NVlabs/nvdiffrast
pip install "git+https://github.com/facebookresearch/pytorch3d.git@stable"

# 7. Instalar diffusers customizado
cd Kiss3DGen
pip install -e custom_diffusers/
cd ..
# 8. PrÃ©-compilar nvdiffrast (opcional mas recomendado)
python scripts/precompile_nvdiffrast.py --clean
```

## ğŸ“ Estrutura do Projeto

```
mesh3d-generator/
â”œâ”€â”€ mesh3d_generator/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ llm/                    # Etapa 0: GeraÃ§Ã£o de texto a partir de imagens
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â””â”€â”€ text_generator.py
â”‚   â”œâ”€â”€ normal_maps/            # Etapa 1: GeraÃ§Ã£o de normal maps
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â””â”€â”€ generator.py
â”‚   â”œâ”€â”€ mesh_initialization/    # Etapa 2: InicializaÃ§Ã£o da malha
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ lrm.py
â”‚   â”‚   â””â”€â”€ instant_mesh.py
â”‚   â”œâ”€â”€ mesh_refinement/        # Etapa 3: Refinamento da malha
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â””â”€â”€ refiner.py
â”‚   â”œâ”€â”€ utils/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ data_loader.py
â”‚   â”‚   â””â”€â”€ visualization.py
â”‚   â””â”€â”€ config/
â”‚       â””â”€â”€ config.yaml
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ raw/                   # Imagens de entrada
â”‚   â”œâ”€â”€ processed/
â”‚   â””â”€â”€ outputs/               # Malhas 3D geradas
â”œâ”€â”€ notebooks/
â”‚   â””â”€â”€ experiments.ipynb
â”œâ”€â”€ tests/
â”‚   â””â”€â”€ test_basic.py
â”œâ”€â”€ scripts/
â”‚   â”œâ”€â”€ download_dataset.py
â”‚   â”œâ”€â”€ run_pipeline.py
â”‚   â””â”€â”€ test_ollama.py
â”œâ”€â”€ pyproject.toml
â”œâ”€â”€ README.md
â”œâ”€â”€ PLANNING.md
â””â”€â”€ .gitignore
```

## ğŸƒâ€â™€ï¸ Executando o Pipeline

### Um Ãºnico objeto (imagem local)

```powershell
.\mesh3d-generator-py3.11\Scripts\python.exe scripts\run_kiss3dgen_image_to_3d.py `
    --input "data/inputs/bottle.png" `
    --output "outputs/bottle_generation" `
    --config "pipeline_config/default.yaml" `
    --pipeline-mode flux `
    --enable-redux `
    --use-controlnet `
    --use-mv-rgb
```

ParÃ¢metros Ãºteis:

- `--fast-mode`: reduz consumo de VRAM (desliga Redux/ControlNet e forÃ§a limpeza agressiva de modelos).
- `--pipeline-mode multiview`: usa Zero123++ diretamente (sem Flux), exigindo menos VRAM porÃ©m com menos fidelidade.
- `--dataset-item` / `--dataset-view`: seleciona imagens prontas em `data/raw/gazebo_dataset/images`.
- `--dataset-plan`: executa um YAML com vÃ¡rios objetos em sequÃªncia.
- `--gt-mesh`: fornece mesh de referÃªncia para cÃ¡lculo automÃ¡tico de Chamfer/F-score.

Resultados:

- `outputs/<uuid>.obj/.glb`: mesh direto do LRM (sem ISOMER) â€” usa vertex colors preservados e Ã© o fallback quando o nvdiffrast falha.
- `outputs/<uuid>_isomer.obj/.glb`: mesh refinado pelo ISOMER (necessita `renderutils_plugin` funcional).
- `outputs/tmp/`: contÃ©m bundles intermediÃ¡rios (`*_flux_seed_bundle.png`, `*_generated_bundle.png`, `*_recon_from_kiss3d.png`) usados para depuraÃ§Ã£o de cores.

### Batch com vÃ¡rios objetos (dataset plan)

```powershell
python scripts/run_kiss3dgen_image_to_3d.py `
    --dataset-plan pipeline_config/flux_top10_dataset.yaml `
    --output outputs/flux_top10_dataset `
    --pipeline-mode flux `
    --fast-mode
```

Cada entrada do YAML gera um diretÃ³rio em `outputs/<name>_<uuid>/views/*` e um `runs_report.json` com mÃ©tricas ordenadas. Use essa abordagem para processar o dataset do Gazebo ou qualquer CSV/YAML prÃ³prio (basta apontar `--dataset-root`).

## ğŸ“… Schedule e Timeline

Consulte o arquivo [PLANNING.md](PLANNING.md) para o planejamento detalhado e cronograma completo.

### Resumo do Cronograma

- **Semana 1-2**: Setup do ambiente e estudo do Kiss3DGen
- **Semana 3-4**: ImplementaÃ§Ã£o da geraÃ§Ã£o de texto detalhado com LLM multimodal a partir de imagens
- **Semana 5-6**: ImplementaÃ§Ã£o da geraÃ§Ã£o de Normal Maps
- **Semana 7-8**: ImplementaÃ§Ã£o da inicializaÃ§Ã£o de malha (LRM/InstantMesh)
- **Semana 9-10**: ImplementaÃ§Ã£o do refinamento de malha
- **Semana 11-12**: IntegraÃ§Ã£o completa do pipeline (texto + normal maps + refinamento)
- **Semana 13-14**: Testes e validaÃ§Ã£o com dataset do Google Research
- **Semana 15-16**: Refinamentos finais e documentaÃ§Ã£o

## ğŸ”§ Uso BÃ¡sico

```python
from mesh3d_generator import TextGenerator, NormalMapGenerator, MeshRefiner
from mesh3d_generator.mesh_initialization import InstantMeshInitializer
from PIL import Image

# 1. Gerar texto detalhado a partir da imagem
text_generator = TextGenerator()
image = Image.open("data/raw/chair.jpg")
detailed_text = text_generator.generate_from_image(image)

# 2. Gerar normal map
normal_generator = NormalMapGenerator()
normal_map = normal_generator.generate(image)

# 3. Inicializar malha
mesh_initializer = InstantMeshInitializer()
mesh = mesh_initializer.initialize(image, normal_map)

# 4. Refinar malha com texto e normal map
mesh_refiner = MeshRefiner()
refined_mesh = mesh_refiner.refine(mesh, detailed_text, normal_map)

# 5. Salvar a malha
refined_mesh.export("outputs/chair.obj")
```

## ğŸ¤– IntegraÃ§Ã£o com Ollama

O projeto usa **Ollama** para modelos LLM locais, incluindo modelos multimodais para anÃ¡lise de imagens e geraÃ§Ã£o de descriÃ§Ãµes detalhadas.

### Setup RÃ¡pido
```bash
# Instalar Ollama (se ainda nÃ£o tiver)
# Windows: https://ollama.com/download
# Linux/Mac: curl -fsSL https://ollama.com/install.sh | sh

# Instalar modelos
ollama pull llama3.2  # Modelo textual (opcional, para melhorias de texto)
ollama pull llava     # Modelo multimodal (ESSENCIAL - para anÃ¡lise de imagens)

# Testar integraÃ§Ã£o
poetry run python scripts/test_ollama.py
```

### Uso do LLM Multimodal

```python
from mesh3d_generator import TextGenerator
from PIL import Image

# Inicializar gerador com modelo multimodal
text_generator = TextGenerator(
    model_name="llama3.2",      # Para processamento de texto
    multimodal_model="llava"    # Para anÃ¡lise de imagens
)

# Gerar descriÃ§Ã£o detalhada a partir de imagem
image = Image.open("data/raw/scene.jpg")
detailed_description = text_generator.generate_from_image(image)
print(detailed_description)
```

## ğŸ“š Recursos

- **Dataset**: [Google Research Dataset](https://app.gazebosim.org/GoogleResearch)
- **Codebase Base**: [Kiss3DGen](https://github.com/EnVision-Research/Kiss3DGen)
- **ConferÃªncia**: [CVPR 2025](https://openaccess.thecvf.com/CVPR2025)
- **Ollama**: [DocumentaÃ§Ã£o](https://github.com/ollama/ollama)

## ğŸ¤ ContribuiÃ§Ã£o

Este Ã© um projeto acadÃªmico. Para contribuiÃ§Ãµes, por favor abra uma issue ou pull request.

## ğŸ“ LicenÃ§a

Este projeto Ã© para fins acadÃªmicos.


